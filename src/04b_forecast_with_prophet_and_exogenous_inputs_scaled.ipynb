{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4eae2a34-7b79-47c2-bec6-5f2464ffda10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Daily Forecast with Prophet & Exogenous Variables (Scaled)\n",
    "This notebook generates daily energy consumption forecasts per feeder using a Prophet model augmented with selected exogenous variables. \n",
    "\n",
    "We're looking at this part of the flow:\n",
    "\n",
    "<img src=\"../docs/imgs/energy-sa-forecasting-prophet.png \" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c0966aa8-2c82-41cf-a635-a8a00c391d25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Environment Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c00f1f5-4df5-41ec-9562-6e5539c46b18",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%run ./includes/common_functions_and_imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d10fc997-0119-4b37-a579-cce460e361b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install prophet==1.1.4\n",
    "%pip install holidays\n",
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53d160cf-fca3-4a48-a83a-c745f4995747",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "82d07530-3690-439f-b515-3852154c5b0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Data Ingestion & Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e4985cd-0dde-4d2d-bcbe-aaa62a8ffec2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "source_table_name = (\n",
    "  f\"{CONFIG.target_catalog}.{CONFIG.target_schema}.unscaled_train_features\"\n",
    ")\n",
    "\n",
    "if not spark.catalog.tableExists(source_table_name):\n",
    "  dbutils.notebook.exit('Source table does not exist')\n",
    "\n",
    "target_table_name = f\"{CONFIG.target_catalog}.{CONFIG.target_schema}.predictions_daily_forecast_scaled\"\n",
    "\n",
    "if spark.catalog.tableExists(target_table_name) and not CONFIG.overwrite_data:\n",
    "  dbutils.notebook.exit('Target table already exists, skipping run to save on processing')\n",
    "  \n",
    "df_training = spark.table(source_table_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21880183-0f3a-4dc2-a686-c2a8a4f60ba2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# For this experiment, we select dynamic regressors based on correlation analysis (see unscaled notebook)\n",
    "selected_regressors = [\"ssrd\", \"aggregated_device_count_active\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0cff9a91-3a92-4073-bb4c-04d590edcc48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_daily = (\n",
    "    df_training\n",
    "    .withColumn(\"ds\", F.date_trunc(\"day\", F.col(\"data_collection_log_timestamp\")))\n",
    "    .groupBy(\"lv_feeder_unique_id\", \"ds\")\n",
    "    .agg(\n",
    "        F.sum(\"normalized_consumption_kwh\").alias(\"y\"),\n",
    "        *[F.avg(r).alias(r) for r in selected_regressors]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "44e7635a-5337-4c77-9b99-47330d3cb13f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Scaling & Forecast Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0d5e5f20-26e0-4215-b11a-8ace0f089929",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "SSRD (surface solar radiation downwards) and active device count were chosen because they exhibit significant day‑to‑day variability and demonstrated the strongest correlations with daily consumption (|corr| ≈ 0.19 and |corr| ≈ 0.15, respectively). Including these dynamic covariates complements Prophet’s built‑in seasonal components to capture external demand drivers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "feebe483-ae23-4496-8b29-e172f313bac4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define the function that will be applied to each feeder’s daily data via Pandas UDF.\n",
    "# It fits a Prophet model on historical daily observations and forecasts into the future.\n",
    "def apply_forecast_daily(pdf):\n",
    "    # If there are less than 2 non-NaN rows, return an empty DataFrame with correct columns.\n",
    "    if pdf.shape[0] < 2:\n",
    "        return pd.DataFrame(columns=[\"lv_feeder_unique_id\", \"ds\", \"yhat\"])\n",
    "    \n",
    "    # Define forecast horizon locally.\n",
    "    forecast_horizon = 90  # Adjust as needed.\n",
    "    \n",
    "    changepoint_prior_scale = 0.01\n",
    "    seasonality_mode = 'multiplicative'\n",
    "    n_changepoints = 50  # Adjust if necessary.\n",
    "    \n",
    "    # Initialize and configure the Prophet model.\n",
    "    m = Prophet(\n",
    "        changepoint_prior_scale=changepoint_prior_scale,\n",
    "        seasonality_mode=seasonality_mode,\n",
    "        daily_seasonality=True\n",
    "    ).add_country_holidays(country_name=\"GB\")\\\n",
    "     .add_seasonality(name=\"weekly\", period=7, fourier_order=3)\\\n",
    "     .add_seasonality(name=\"annual\", period=365, fourier_order=10)\n",
    "     \n",
    "    # Optionally, add regressors if your pdf contains those columns.\n",
    "    for reg in selected_regressors:\n",
    "        if reg in pdf.columns:\n",
    "            m.add_regressor(reg)\n",
    "    \n",
    "    # Fit the model on this feeder's historical data.\n",
    "    m.fit(pdf)\n",
    "    \n",
    "    # Create a future DataFrame for the forecast horizon using daily frequency.\n",
    "    future = m.make_future_dataframe(periods=forecast_horizon, freq='D', include_history=False)\n",
    "    \n",
    "    # For additional regressors, fill in the future DataFrame with the last observed values.\n",
    "    last_vals = pdf.iloc[-1][selected_regressors].to_dict() \\\n",
    "                if set(selected_regressors).issubset(pdf.columns) \\\n",
    "                else {}\n",
    "    for reg in last_vals:\n",
    "        future[reg] = last_vals[reg]\n",
    "    \n",
    "    # Generate forecast using Prophet.\n",
    "    forecast = m.predict(future)[[\"ds\", \"yhat\"]]\n",
    "    forecast[\"lv_feeder_unique_id\"] = pdf[\"lv_feeder_unique_id\"].iloc[0]\n",
    "    \n",
    "    return forecast[[\"lv_feeder_unique_id\", \"ds\", \"yhat\"]]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9113fd2-5edb-4ba8-ba75-56cc0e47158d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "output_schema = T.StructType([\n",
    "    T.StructField(\"lv_feeder_unique_id\", T.StringType(), True),\n",
    "    T.StructField(\"ds\", T.DateType(), True),\n",
    "    T.StructField(\"yhat\", T.DoubleType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9bd51f8a-4299-42e4-8cc2-1ae8e4ade717",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Apply the forecasting function per feeder using applyInPandas.\n",
    "results_df = df_daily.groupBy(\"lv_feeder_unique_id\").applyInPandas(apply_forecast_daily, schema=output_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dfbf4583-a861-47de-8807-3862ad3f3cd2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "results_df.write.mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(target_table_name)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "04b_forecast_with_prophet_and_exogenous_inputs_scaled",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
