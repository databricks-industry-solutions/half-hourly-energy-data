{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6da750a4-3a08-48ed-8844-a8015ed13636",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Notebook Documentation: Daily Forecast with Prophet & Exogenous Variables (Unscaled)\n",
    "This notebook generates daily energy consumption forecasts per feeder using a Prophet model augmented with selected exogenous variables.\n",
    "\n",
    "We're looking at this part of the flow:\n",
    "\n",
    "<img src=\"../docs/imgs/energy-sa-forecasting-prophet.png \" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf5e9649-00f5-4e45-820b-de178dbf1acc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Environment Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e241562e-104a-49ab-90a6-e416133f277c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%run ./includes/common_functions_and_imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "900c0763-2d8d-4714-9d17-7080f482a75e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install prophet==1.1.4\n",
    "%pip install holidays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef4386df-7b52-4ae5-99da-aa6181252f07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from prophet import Prophet\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import IntegerType, FloatType, DoubleType, LongType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "828b933e-6fa7-4e0a-813c-63bf6f0bded9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Data Ingestion & Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff59d11e-0481-4f35-aa11-81eba12f8cca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "source_table_name = (\n",
    "  f\"{CONFIG.target_catalog}.{CONFIG.target_schema}.unscaled_train_features\"\n",
    ")\n",
    "\n",
    "if not spark.catalog.tableExists(source_table_name):\n",
    "  dbutils.notebook.exit('Source table does not exist')\n",
    "\n",
    "target_table_name = f\"{CONFIG.target_catalog}.{CONFIG.target_schema}.predictions_daily_forecast_exogenous_noscaling_ext\"\n",
    "\n",
    "if spark.catalog.tableExists(target_table_name) and not CONFIG.overwrite_data:\n",
    "  dbutils.notebook.exit('Target table already exists, skipping run to save on processing')\n",
    "  \n",
    "df_training = spark.table(source_table_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42449782-4a2e-45d5-b6c6-63546e5c392b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Aggregate the data to a daily level by truncating the timestamp to 'day'\n",
    "# and computing the sum of normalized_consumption_kwh as the target (y)\n",
    "# and averages for the numerical regressors.\n",
    "df_daily = (\n",
    "  df_training\n",
    "    .withColumn(\"ds\", F.date_trunc(\"day\", F.col(\"data_collection_log_timestamp\")))\n",
    "    .groupBy(\"lv_feeder_unique_id\", \"ds\")                # ← include feeder id here\n",
    "    .agg(\n",
    "      F.sum(\"normalized_consumption_kwh\").alias(\"y\"),\n",
    "      F.avg(\"cyc_halfhour\").alias(\"cyc_halfhour\"),\n",
    "      F.avg(\"cyc_hour\").alias(\"cyc_hour\"),\n",
    "      F.avg(\"approx_distance_to_weather_station\").alias(\"approx_distance_to_weather_station\"),\n",
    "      F.avg(\"aggregated_device_count_active\").alias(\"aggregated_device_count_active\"),\n",
    "      F.avg(\"t2m\").alias(\"t2m\"),\n",
    "      F.avg(\"u10\").alias(\"u10\"),\n",
    "      F.avg(\"v10\").alias(\"v10\"),\n",
    "      F.avg(\"ssrd\").alias(\"ssrd\"),\n",
    "      F.avg(\"strd\").alias(\"strd\"),\n",
    "      F.avg(\"cyc_day\").alias(\"cyc_day\"),\n",
    "      F.avg(\"cyc_week\").alias(\"cyc_week\"),\n",
    "      F.avg(\"cyc_month\").alias(\"cyc_month\"),\n",
    "      F.avg(\"cyc_halfhour_sin\").alias(\"cyc_halfhour_sin\"),\n",
    "      F.avg(\"cyc_halfhour_cos\").alias(\"cyc_halfhour_cos\"),\n",
    "      F.avg(\"cyc_hour_sin\").alias(\"cyc_hour_sin\"),\n",
    "      F.avg(\"cyc_hour_cos\").alias(\"cyc_hour_cos\"),\n",
    "      F.avg(\"cyc_day_sin\").alias(\"cyc_day_sin\"),\n",
    "      F.avg(\"cyc_day_cos\").alias(\"cyc_day_cos\"),\n",
    "      F.avg(\"cyc_week_sin\").alias(\"cyc_week_sin\"),\n",
    "      F.avg(\"cyc_week_cos\").alias(\"cyc_week_cos\"),\n",
    "      F.avg(\"cyc_month_sin\").alias(\"cyc_month_sin\"),\n",
    "      F.avg(\"cyc_month_cos\").alias(\"cyc_month_cos\")\n",
    "    )\n",
    ")\n",
    "\n",
    "df_daily.show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5ed7968d-7585-466e-b238-74084434a90f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Analysis of numerical input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78f72174-22ad-498d-bf0b-fcf270c5452d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "target_col = \"y\"\n",
    "\n",
    "# Extract all numeric columns (excluding the target) from the daily DataFrame.\n",
    "numeric_types = (IntegerType, FloatType, DoubleType, LongType)\n",
    "candidate_cols = [\n",
    "    field.name for field in df_daily.schema.fields \n",
    "    if isinstance(field.dataType, numeric_types) and field.name != target_col\n",
    "]\n",
    "\n",
    "print(\"Candidate numerical columns:\")\n",
    "print(candidate_cols)\n",
    "\n",
    "# Compute the Pearson correlation between the target variable and each candidate column.\n",
    "correlations = []\n",
    "for col_name in candidate_cols:\n",
    "    try:\n",
    "        corr_val = df_daily.stat.corr(target_col, col_name)\n",
    "        correlations.append((col_name, corr_val))\n",
    "    except Exception as e:\n",
    "        print(f\"Error computing correlation for {col_name}: {e}\")\n",
    "\n",
    "# Sort the correlations by the absolute value (strongest correlations first).\n",
    "sorted_correlations = sorted(correlations, key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "print(\"Correlations with\", target_col, \"sorted by absolute value (highest to lowest):\")\n",
    "for col_name, corr_val in sorted_correlations:\n",
    "    print(f\"{col_name}: {corr_val:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e747b4b9-9fe9-4f63-87b1-e31146673e32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Based on the correlations, we will focus on the exogenous regressors on the truly dynamic, non‐seasonal drivers, especially since Prophet already handles weekly/annual cycles internally. In particular:\n",
    "\n",
    "* t2m (mean daily temperature): |corr| ≈ 0.268\n",
    "* ssrd (surface solar radiation downwards): |corr| ≈ 0.187\n",
    "* strd (surface solar radiation upwelling): |corr| ≈ 0.140\n",
    "* aggregated_device_count_active: |corr| ≈ 0.145"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e83f6f09-9ca2-407f-88ef-54ad906b612a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Forecast Function (Pandas UDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7ecfccc2-3bbd-4c1c-a907-16ea833cef38",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "t2m (mean daily temperature), ssrd (surface solar radiation downwards), strd (surface solar radiation upwelling), and aggregated_device_count_active were selected due to their day‑to‑day variability and significant correlations with daily consumption (|corr| ≈ 0.268, 0.187, 0.140, and 0.145, respectively). Including these covariates enhances Prophet’s seasonal trend modeling by capturing external drivers such as temperature fluctuations, solar energy availability, and device usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c27ebabd-201e-4f8f-b0c0-fcef950271c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Forecast horizon (number of days to forecast)\n",
    "forecast_horizon = 90  # Adjust as needed (e.g., to cover your test period)\n",
    "\n",
    "# Selected regressors based on prior analysis\n",
    "selected_regressors = [\"t2m\", \"ssrd\", \"strd\", \"aggregated_device_count_active\"]\n",
    "\n",
    "# Prophet hyperparameters (tune these if necessary)\n",
    "changepoint_prior_scale = 0.05   # Increased for more flexibility\n",
    "seasonality_mode = 'additive'    # Can try additive if multiplicative is unstable\n",
    "n_changepoints = 50              # Number of potential changepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ae8b64f-0983-4abc-82e3-31d25b57b251",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Reduces the dataframe to include only the selected regressors\n",
    "df_daily = (\n",
    "    df_training.withColumn(\n",
    "        \"ds\", F.date_trunc(\"day\", F.col(\"data_collection_log_timestamp\"))\n",
    "    )\n",
    "    .groupBy(\"lv_feeder_unique_id\", \"ds\")\n",
    "    .agg(\n",
    "        F.sum(\"normalized_consumption_kwh\").alias(\"y\"),\n",
    "        *[F.avg(r).alias(r) for r in selected_regressors]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f88546a4-aa57-470e-a95d-cbcb02463280",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def apply_forecast_daily_noscaling(pdf):\n",
    "    # If there are fewer than 2 non-NaN rows, return empty.\n",
    "    if pdf.shape[0] < 2:\n",
    "        return pd.DataFrame(columns=[\"lv_feeder_unique_id\", \"ds\", \"yhat\"])\n",
    "    \n",
    "    # Ensure the 'ds' column is datetime.\n",
    "    pdf['ds'] = pd.to_datetime(pdf['ds'])\n",
    "    \n",
    "    # Initialize Prophet with the defined hyperparameters.\n",
    "    m = Prophet(\n",
    "            changepoint_prior_scale=changepoint_prior_scale,\n",
    "            seasonality_mode=seasonality_mode,\n",
    "            daily_seasonality=True\n",
    "        ).add_country_holidays(country_name=\"GB\")\\\n",
    "         .add_seasonality(name=\"weekly\", period=7, fourier_order=3)\\\n",
    "         .add_seasonality(name=\"annual\", period=365, fourier_order=10)\n",
    "         \n",
    "    # Add the selected extra regressors directly, without scaling.\n",
    "    for reg in selected_regressors:\n",
    "        if reg in pdf.columns:\n",
    "            m.add_regressor(reg)\n",
    "    \n",
    "    # Fit the Prophet model on this feeder's historical daily data.\n",
    "    try:\n",
    "        m.fit(pdf)\n",
    "    except Exception as e:\n",
    "        # In case of any model fitting issues, return an empty DataFrame.\n",
    "        return pd.DataFrame(columns=[\"lv_feeder_unique_id\", \"ds\", \"yhat\"])\n",
    "    \n",
    "    # Create a future DataFrame for the forecast horizon using daily frequency.\n",
    "    future = m.make_future_dataframe(periods=forecast_horizon, freq='D', include_history=False)\n",
    "    \n",
    "    # Fill in the extra regressors in the future DataFrame with the last observed values.\n",
    "    last_vals = pdf.iloc[-1][selected_regressors].to_dict() if set(selected_regressors).issubset(pdf.columns) else {}\n",
    "    for reg in last_vals:\n",
    "        future[reg] = last_vals[reg]\n",
    "    \n",
    "    # Generate forecast using Prophet.\n",
    "    forecast = m.predict(future)[[\"ds\", \"yhat\"]]\n",
    "    forecast[\"lv_feeder_unique_id\"] = pdf[\"lv_feeder_unique_id\"].iloc[0]\n",
    "    \n",
    "    return forecast[[\"lv_feeder_unique_id\", \"ds\", \"yhat\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f8fd1d7-37ce-4cae-80e1-b3d06b3bb12c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "output_schema = T.StructType([\n",
    "    T.StructField(\"lv_feeder_unique_id\", T.StringType(), True),\n",
    "    T.StructField(\"ds\", T.DateType(), True),\n",
    "    T.StructField(\"yhat\", T.DoubleType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9a97b5a-d6d8-44db-bd7e-9fde39a09ace",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Apply the forecasting function per feeder using applyInPandas.\n",
    "results_df = df_daily.groupBy(\"lv_feeder_unique_id\").applyInPandas(apply_forecast_daily_noscaling, schema=output_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "319252aa-0f6f-4ea9-a993-d99156859e78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Write the forecast results to a table for downstream analysis.\n",
    "results_df.write.mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(target_table_name)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "04a_forecast_with_prophet_and_exogenous_inputs_unscaled",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
