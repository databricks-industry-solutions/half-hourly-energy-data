{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "db52dae2-ce18-44e1-a848-85a824ac6fd0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Common functions notebook\n",
    "\n",
    "This notebook is shared between all notebooks to perform common activities and provide reusable functions.\n",
    "\n",
    "Intended to be run with `%run ...`, will not execute standalone.\n",
    "\n",
    "### Imports\n",
    "\n",
    "- pandas ➡️ `pd`\n",
    "- geopandas ➡️ `gpd`\n",
    "- pyspark functions ➡️ `F`\n",
    "- pyspark window ➡️ `Window`\n",
    "\n",
    "\n",
    "### Variables exposed\n",
    "\n",
    "- `CONFIG` : Provides catalog, schema and secret lookup values as attributes.\n",
    "### Functions provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca88ddfc-931a-405c-9c20-d1fa8c79231e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Install from requirements"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%pip install -r ./requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "09e3a02b-6beb-4023-a562-631fc8ba4357",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Set auto-reload for local library changes"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d9c6803-c403-4800-a284-69dca7155378",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.window import Window\n",
    "import os\n",
    "# Imports used by setup\n",
    "from pprint import pprint\n",
    "import json\n",
    "from pydantic import BaseModel\n",
    "from typing import Any, Dict\n",
    "from pathlib import Path\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a905231-1366-43e0-91e7-9bd1bd3e282b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Config parser"
    }
   },
   "outputs": [],
   "source": [
    "  \n",
    "class MyConfig(BaseModel):\n",
    "    \"\"\"Pydantic Config model to process the solution accelerator configs from a json file.\"\"\"\n",
    "    target_catalog: str\n",
    "    target_schema: str\n",
    "    secret_scope: str\n",
    "    secret_key: str\n",
    "    clone_raw_data: bool\n",
    "    overwrite_data: bool\n",
    "    \n",
    "    @classmethod\n",
    "    def from_json(cls, json_path: str) -> \"Config\":\n",
    "        \"\"\"Load configuration from a JSON file.\n",
    "        \n",
    "        Args:\n",
    "            json_path: Path to the JSON configuration file\n",
    "            \n",
    "        Returns:\n",
    "            Config object with attributes matching the JSON keys\n",
    "        \"\"\"\n",
    "        path = Path(json_path)\n",
    "        if not path.exists():\n",
    "            raise FileNotFoundError(f\"Config file not found: {json_path}\")\n",
    "            \n",
    "        with open(path, \"r\") as f:\n",
    "            config_data = json.load(f)\n",
    "        return cls(**config_data)\n",
    "\n",
    "\n",
    "json_config_path = glob.glob('**/config.json', recursive=True)[0]\n",
    "\n",
    "CONFIG = MyConfig.from_json(json_config_path)\n",
    "print(f\"Config created with schema:\")\n",
    "pprint(CONFIG.schema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a6300b4a-a421-449c-96d1-4126cd5a8ede",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Helper functions"
    }
   },
   "outputs": [],
   "source": [
    "# Simple helper function to convert our pandas dataframe with x, y grid coordinate data into a geopandas dataframe\n",
    "def to_geodf(df: pd.DataFrame, sample_frac: float) -> gpd.GeoDataFrame:\n",
    "  df[\"geom\"] = gpd.points_from_xy(df.x, df.y, crs=\"EPSG:4326\")\n",
    "  return gpd.GeoDataFrame(\n",
    "    df.sample(frac=sample_frac, random_state=42),\n",
    "    geometry=\"geom\"\n",
    "  )"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "common_functions_and_imports",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
